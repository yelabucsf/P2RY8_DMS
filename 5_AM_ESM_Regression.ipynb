{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ba1fd7-c0aa-410d-a2e2-f37b6b4269db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert into the ohe from chloe hsu code\n",
    "import numpy as np\n",
    "# stuff to perform chloe hsu augment\n",
    "# note does not have an error handling component for if KeyError\n",
    "aa_to_int = {\n",
    "    'M':1,\n",
    "    'R':2,\n",
    "    'H':3,\n",
    "    'K':4,\n",
    "    'D':5,\n",
    "    'E':6,\n",
    "    'S':7,\n",
    "    'T':8,\n",
    "    'N':9,\n",
    "    'Q':10, 'C':11,\n",
    "    'U':12,\n",
    "    'G':13,\n",
    "    'P':14,\n",
    "    'A':15,\n",
    "    'V':16,\n",
    "    'I':17,\n",
    "    'F':18,\n",
    "    'Y':19,\n",
    "    'W':20,\n",
    "    'L':21,\n",
    "    'O':22, #Pyrrolysine\n",
    "    'X':23, # Unknown\n",
    "    'Z':23, # Glutamic acid or GLutamine\n",
    "    'B':23, # Asparagine or aspartic acid\n",
    "    'J':23, # Leucine or isoleucine\n",
    "    'start':24,\n",
    "    'stop':25,\n",
    "    '-':26,\n",
    "}\n",
    "\n",
    "def aa_seq_to_int(s):\n",
    "    \"\"\"\n",
    "    Return the int sequence as a list for a given string of amino acids\n",
    "    \"\"\"\n",
    "    return [aa_to_int[a] for a in s]\n",
    "\n",
    "def format_seq(seq):\n",
    "    \"\"\"\n",
    "    Takes an amino acid sequence, returns a list of integers based on dictionary aa_to_int\n",
    "    \"\"\"\n",
    "    int_seq = aa_seq_to_int(seq.strip())\n",
    "    return int_seq\n",
    "\n",
    "# converts sequences to integers, insures all are same length\n",
    "def format_batch_seqs(seqs):\n",
    "    maxlen = -1\n",
    "    for s in seqs:\n",
    "        if len(s) > maxlen:\n",
    "            maxlen = len(s)\n",
    "    formatted = []\n",
    "    for seq in seqs:\n",
    "        pad_len = maxlen - len(seq)\n",
    "        padded = np.pad(format_seq(seq), (0, pad_len), 'constant', constant_values=0)\n",
    "        formatted.append(padded)\n",
    "    return np.stack(formatted)\n",
    "\n",
    "def seqs_to_onehot(seqs):\n",
    "    X = np.zeros((seqs.shape[0], seqs.shape[1]*24), dtype=int)\n",
    "    for i in range(seqs.shape[1]):\n",
    "        for j in range(24):\n",
    "            X[:, i*24+j] = (seqs[:, i] == j)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dc4ab0-2f43-4eeb-8f85-46e77feb298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep OHE with position, full_var, AM_pathogenicity, and ESM1_b score \n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "def ohe_all(df):\n",
    "    # pull variant sequences and one hot encode\n",
    "    ls_df = df.loc[:,\"full_var_seq\"]\n",
    "    df_temp1 = format_batch_seqs(ls_df)\n",
    "    df_temp2 = seqs_to_onehot(df_temp1)\n",
    "    # pull columns that I want to keep from df_ms1\n",
    "    df_ohe = np.column_stack((df[\"pos\"].values, df[\"full_var\"].values, df[\"wt_aa\"].values, df[\"var_aa\"].values, df[\"am_pathogenicity\"].values, df[\"ESM1b_score\"].values,\n",
    "                             df[\"Expr_z_score\"].values, df[\"Migr_z_score\"].values, df[\"Prolif_z_score\"].values))\n",
    "    # transform AM_path and ESM1b to percentile based scores\n",
    "    qt_am_pathogenicity = QuantileTransformer(n_quantiles=1000, output_distribution=\"uniform\")\n",
    "    qt_ESM1b_score = QuantileTransformer(n_quantiles=1000, output_distribution=\"uniform\")\n",
    "    am_pathogenicity_quant = qt_am_pathogenicity.fit_transform(df_ohe[:, 4].reshape(-1, 1))  # Assuming \"am_pathogenicity\" is the 5th column\n",
    "    ESM1b_score_quant = qt_ESM1b_score.fit_transform(df_ohe[:, 5].reshape(-1, 1))  # Assuming \"ESM1b_score\" is the 6th column\n",
    "    # combine everything together and return as df\n",
    "    df_ohe = np.column_stack((df_ohe, am_pathogenicity_quant, ESM1b_score_quant, df_temp2))  \n",
    "    column_names = [\"pos\", \"full_var\", \"wt_aa\", \"var_aa\", \"am_pathogenicity\", \"ESM1b_score\", \"Expr_z_score\", \"Migr_z_score\", \"Prolif_z_score\",\n",
    "                    \"am_pathogenicity_quant\", \"ESM1b_score_quant\"] + ['feature_' + str(i) for i in range(df_temp2.shape[1])]\n",
    "    df_final = pd.DataFrame(df_ohe, columns=column_names)\n",
    "    return df_final\n",
    "\n",
    "# random sampling within each position \n",
    "def split_dataframe_random(df, k):\n",
    "    # make sure it's not the WT sub\n",
    "    df_filtered = df[df[\"wt_aa\"] != df[\"var_aa\"]]\n",
    "    df_sample = df_filtered.sample(n=k)\n",
    "    remaining_df = df.drop(df_sample.index)\n",
    "    return df_sample, remaining_df\n",
    "\n",
    "def run_ridge_prep(df_x, k, predictor):\n",
    "    #Group the dataframe by pos and use split_data_frame function to randomly sample k rows (df1), df2 remainder \n",
    "    grouped = df_x.groupby('pos').apply(lambda x: split_dataframe_random(x, k))\n",
    "    # Initialize empty dataframes for storing the results\n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    for _, (df_sample, remaining_df) in grouped.items():\n",
    "        df1 = pd.concat([df1, df_sample])\n",
    "        df2 = pd.concat([df2, remaining_df])\n",
    "    oh1 = df1.iloc[:, 11:]\n",
    "    oh2 = df2.iloc[:, 11:]\n",
    "    train_x = np.column_stack((df1[predictor].values, oh1))\n",
    "    test_x = np.column_stack((df2[predictor].values,oh2))\n",
    "    return df1, df2, train_x, test_x\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "def run_ridge(train_x, train_y, test_x, test_y):\n",
    "    # train default linear regression\n",
    "    lm = Ridge() \n",
    "    lm.fit(train_x, train_y)\n",
    "    pred_y = lm.predict(test_x)\n",
    "    return pred_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc6da7a-6afb-4ebb-b8ae-f97fc02dc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary sequence, ESM1b, and AM data \n",
    "import pandas as pd\n",
    "df_var = pd.read_csv(\"C38_42_All_var_AM.csv\", delimiter = ',', header = 0)\n",
    "# subset with only missense variants (no synonymous)\n",
    "df_ms = df_var[df_var[\"wt_aa\"] != df_var[\"var_aa\"]]\n",
    "df_ms = df_ms.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0283934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with seqs one-hot + am pathogenicity \n",
    "# One hot encode all the sequences\n",
    "df_ohe_all = ohe_all(df_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4994f98d-fb1f-4b8e-b418-805f35f0997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(200):\n",
    "    # Random sampling + OHE \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 2, \"am_pathogenicity\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i+800}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc112818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_am_ohllr_exp9-10.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_am_ohllr_mig9-10.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_am_ohllr_prol9-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f10ec67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_esm_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 2, \"ESM1b_score\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i+900}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_esm_ohllr_exp = df_esm_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_esm_ohllr_mig = df_esm_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_esm_ohllr_prol = df_esm_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2d4c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esm_ohllr_exp.to_csv(\"df_esm_ohllr_exp10.csv\")\n",
    "df_esm_ohllr_mig.to_csv(\"df_esm_ohllr_mig10.csv\")\n",
    "df_esm_ohllr_prol.to_csv(\"df_esm_ohllr_prol10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc587c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(500):\n",
    "    # Random sampling + OHE \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 2, \"am_pathogenicity_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i+500}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2041003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_amquant_ohllr_exp6-10.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_amquant_ohllr_mig6-10.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_amquant_ohllr_prol6-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be70ceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(900):\n",
    "    # Random sampling + OHE; 4 variants per position rather than 2  \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 4, \"am_pathogenicity_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i+100}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c93e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_amquant_ohllr4_exp2-10.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_amquant_ohllr4_mig2-10.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_amquant_ohllr4_prol2-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a0db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE; 8 variants per position rather than 2  \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 8, \"am_pathogenicity_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908167e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_amquant_ohllr8_exp1.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_amquant_ohllr8_mig1.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_amquant_ohllr8_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c363fcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE; 12 variants per position rather than 2\n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 12, \"am_pathogenicity_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df5bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_amquant_ohllr12_exp1.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_amquant_ohllr12_mig1.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_amquant_ohllr12_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74aad7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE; 16 variants per position rather than 2\n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 16, \"am_pathogenicity_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb974e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_amquant_ohllr16_exp1.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_amquant_ohllr16_mig1.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_amquant_ohllr16_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f55258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_esm_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(900):\n",
    "    # Random sampling + OHE \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 2, \"ESM1b_score_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i+100}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_esm_ohllr_exp = df_esm_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_esm_ohllr_mig = df_esm_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_esm_ohllr_prol = df_esm_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6887da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esm_ohllr_exp.to_csv(\"df_esmquant_ohllr_exp2-10.csv\")\n",
    "df_esm_ohllr_mig.to_csv(\"df_esmquant_ohllr_mig2-10.csv\")\n",
    "df_esm_ohllr_prol.to_csv(\"df_esmquant_ohllr_prol2-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7d791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_esm_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE, 4 variants per position rather than 2 \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 4, \"ESM1b_score_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_esm_ohllr_exp = df_esm_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_esm_ohllr_mig = df_esm_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_esm_ohllr_prol = df_esm_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a265e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esm_ohllr_exp.to_csv(\"df_esmquant4_ohllr_exp1.csv\")\n",
    "df_esm_ohllr_mig.to_csv(\"df_esmquant4_ohllr_mig1.csv\")\n",
    "df_esm_ohllr_prol.to_csv(\"df_esmquant4_ohllr_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7edbc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_esm_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE, 8 variants per position rather than 2 \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 8, \"ESM1b_score_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_esm_ohllr_exp = df_esm_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_esm_ohllr_mig = df_esm_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_esm_ohllr_prol = df_esm_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "814a2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esm_ohllr_exp.to_csv(\"df_esmquant8_ohllr_exp1.csv\")\n",
    "df_esm_ohllr_mig.to_csv(\"df_esmquant8_ohllr_mig1.csv\")\n",
    "df_esm_ohllr_prol.to_csv(\"df_esmquant8_ohllr_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "454adddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_esm_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE, 12 variants per position rather than 2 \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 12, \"ESM1b_score_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_esm_ohllr_exp = df_esm_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_esm_ohllr_mig = df_esm_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_esm_ohllr_prol = df_esm_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e02f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esm_ohllr_exp.to_csv(\"df_esmquant12_ohllr_exp1.csv\")\n",
    "df_esm_ohllr_mig.to_csv(\"df_esmquant12_ohllr_mig1.csv\")\n",
    "df_esm_ohllr_prol.to_csv(\"df_esmquant12_ohllr_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a9663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_esm_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_esm_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE, 16 variants per position rather than 2 \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_all, 16, \"ESM1b_score_quant\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_esm_ohllr_exp = df_esm_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_esm_ohllr_mig = df_esm_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_esm_ohllr_prol = df_esm_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09225c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esm_ohllr_exp.to_csv(\"df_esmquant16_ohllr_exp1.csv\")\n",
    "df_esm_ohllr_mig.to_csv(\"df_esmquant16_ohllr_mig1.csv\")\n",
    "df_esm_ohllr_prol.to_csv(\"df_esmquant16_ohllr_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb17d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New column with logit transformed am pathogenicity values\n",
    "df_ms2 = df_ms\n",
    "df_ms2['logit_am_path'] = np.log(df_ms2['am_pathogenicity'] / (1 - df_ms2['am_pathogenicity']))\n",
    "\n",
    "def ohe_all_unnormed(df):\n",
    "    # pull variant sequences and one hot encode\n",
    "    ls_df = df.loc[:,\"full_var_seq\"]\n",
    "    df_temp1 = format_batch_seqs(ls_df)\n",
    "    df_temp2 = seqs_to_onehot(df_temp1)\n",
    "    # pull columns that I want to keep from df_ms1\n",
    "    df_ohe = np.column_stack((df[\"pos\"].values, df[\"full_var\"].values, df[\"wt_aa\"].values, df[\"var_aa\"].values, df[\"am_pathogenicity\"].values, df[\"ESM1b_score\"].values,\n",
    "                             df[\"Expr_z_score\"].values, df[\"Migr_z_score\"].values, df[\"Prolif_z_score\"].values, df[\"logit_am_path\"]))\n",
    "   # combine everything together and return as df\n",
    "    df_ohe = np.column_stack((df_ohe, df_temp2))  \n",
    "    column_names = [\"pos\", \"full_var\", \"wt_aa\", \"var_aa\", \"am_pathogenicity\", \"ESM1b_score\", \"Expr_z_score\", \"Migr_z_score\", \"Prolif_z_score\", \"logit_am_path\"] + ['feature_' + str(i) for i in range(df_temp2.shape[1])]\n",
    "    df_final = pd.DataFrame(df_ohe, columns=column_names)\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f54b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with seqs one-hot + am pathogenicity \n",
    "# One hot encode all the sequences\n",
    "df_ohe_logit_all = ohe_all_unnormed(df_ms2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3610d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms2[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms2[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms2[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE \n",
    "    df1, df2, train_x, test_x = run_ridge_prep(df_ohe_logit_all, 2, \"logit_am_path\")\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18df203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_amlogit_ohllr_exp1.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_amlogit_ohllr_mig1.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_amlogit_ohllr_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3e77dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "def run_ridge_prep_oheonly (df_x, k):\n",
    "    #Group the dataframe by pos and use split_data_frame function to randomly sample k rows (df1), df2 remainder \n",
    "    grouped = df_x.groupby('pos').apply(lambda x: split_dataframe_random(x, k))\n",
    "    # Initialize empty dataframes for storing the results\n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    for _, (df_sample, remaining_df) in grouped.items():\n",
    "        df1 = pd.concat([df1, df_sample])\n",
    "        df2 = pd.concat([df2, remaining_df])\n",
    "    oh1 = df1.iloc[:, 11:]\n",
    "    oh2 = df2.iloc[:, 11:]\n",
    "    ## modified below from standard run_ridge_prep, no longer incorporating AM pathogenicity or the like \n",
    "    train_x = oh1\n",
    "    test_x = oh2\n",
    "    return df1, df2, train_x, test_x\n",
    "\n",
    "#Create df to hold the predicted values across iterations\n",
    "df_am_ohllr_exp = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_mig = df_ms[[\"full_var\"]].copy()\n",
    "df_am_ohllr_prol = df_ms[[\"full_var\"]].copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # Random sampling + OHE \n",
    "    df1, df2, train_x, test_x = run_ridge_prep_oheonly(df_ohe_all, 2)\n",
    "    # Linear regression for expression, then migration, then proliferation, adding pred values to dfs  \n",
    "    iteration_name = f\"pred_y_{i}\"\n",
    "    pred_y_exp = run_ridge(train_x, df1[\"Expr_z_score\"].values, test_x, df2[\"Expr_z_score\"].values)\n",
    "    df_temp_exp = df2[[\"full_var\"]].copy()\n",
    "    df_temp_exp[iteration_name] = pred_y_exp\n",
    "    df_am_ohllr_exp = df_am_ohllr_exp.merge(df_temp_exp, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_mig = run_ridge(train_x, df1[\"Migr_z_score\"].values, test_x, df2[\"Migr_z_score\"].values)\n",
    "    df_temp_mig = df2[[\"full_var\"]].copy()\n",
    "    df_temp_mig[iteration_name] = pred_y_mig\n",
    "    df_am_ohllr_mig = df_am_ohllr_mig.merge(df_temp_mig, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    pred_y_prol = run_ridge(train_x, df1[\"Prolif_z_score\"].values, test_x, df2[\"Prolif_z_score\"].values)\n",
    "    df_temp_prol = df2[[\"full_var\"]].copy()\n",
    "    df_temp_prol[iteration_name] = pred_y_prol\n",
    "    df_am_ohllr_prol = df_am_ohllr_prol.merge(df_temp_prol, on = \"full_var\", how = \"left\")\n",
    "    \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4b10324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am_ohllr_exp.to_csv(\"df_am_ohe_exp1.csv\")\n",
    "df_am_ohllr_mig.to_csv(\"df_am_ohe_mig1.csv\")\n",
    "df_am_ohllr_prol.to_csv(\"df_am_ohe_prol1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2701cb1-7d40-435b-9e6a-4399a59176f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New df with the averages from the iterations\n",
    "#df_ms = df_ms.reset_index()\n",
    "#df_am_ohllr_all1 = df_ms[[\"full_var\"]].copy()\n",
    "#df_am_ohllr_all1[\"AM_expr_pred\"] = df_am_ohllr_exp.iloc[:,1:4].mean(axis=1)\n",
    "#df_am_ohllr_all1[\"AM_migr_pred\"] = df_am_ohllr_mig.iloc[:,1:4].mean(axis=1)\n",
    "#df_am_ohllr_all1[\"AM_prolif_pred\"] = df_am_ohllr_prol.iloc[:,1:4].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4435535-e6bf-4165-bac7-851575e47530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_var</th>\n",
       "      <th>pred_y_0</th>\n",
       "      <th>pred_y_1</th>\n",
       "      <th>pred_y_2</th>\n",
       "      <th>pred_y_3</th>\n",
       "      <th>pred_y_4</th>\n",
       "      <th>pred_y_5</th>\n",
       "      <th>pred_y_6</th>\n",
       "      <th>pred_y_7</th>\n",
       "      <th>pred_y_8</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_y_90</th>\n",
       "      <th>pred_y_91</th>\n",
       "      <th>pred_y_92</th>\n",
       "      <th>pred_y_93</th>\n",
       "      <th>pred_y_94</th>\n",
       "      <th>pred_y_95</th>\n",
       "      <th>pred_y_96</th>\n",
       "      <th>pred_y_97</th>\n",
       "      <th>pred_y_98</th>\n",
       "      <th>pred_y_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2K</td>\n",
       "      <td>0.335646</td>\n",
       "      <td>0.635340</td>\n",
       "      <td>0.141072</td>\n",
       "      <td>0.224323</td>\n",
       "      <td>0.275930</td>\n",
       "      <td>0.492186</td>\n",
       "      <td>0.539792</td>\n",
       "      <td>0.278752</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731669</td>\n",
       "      <td>1.270759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.651267</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.892014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556771</td>\n",
       "      <td>0.852460</td>\n",
       "      <td>0.635512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2R</td>\n",
       "      <td>0.394582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280856</td>\n",
       "      <td>0.334556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600807</td>\n",
       "      <td>0.338413</td>\n",
       "      <td>0.914320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790348</td>\n",
       "      <td>1.323214</td>\n",
       "      <td>0.301831</td>\n",
       "      <td>0.707054</td>\n",
       "      <td>0.891776</td>\n",
       "      <td>0.948389</td>\n",
       "      <td>0.226279</td>\n",
       "      <td>0.614881</td>\n",
       "      <td>0.911297</td>\n",
       "      <td>0.691873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2H</td>\n",
       "      <td>0.199531</td>\n",
       "      <td>0.500259</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.093760</td>\n",
       "      <td>0.140531</td>\n",
       "      <td>0.356071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140965</td>\n",
       "      <td>0.726704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596149</td>\n",
       "      <td>1.149613</td>\n",
       "      <td>0.116032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707429</td>\n",
       "      <td>0.761814</td>\n",
       "      <td>0.039459</td>\n",
       "      <td>0.422565</td>\n",
       "      <td>0.716575</td>\n",
       "      <td>0.505344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2E</td>\n",
       "      <td>0.420308</td>\n",
       "      <td>0.719359</td>\n",
       "      <td>0.221542</td>\n",
       "      <td>0.305533</td>\n",
       "      <td>0.360147</td>\n",
       "      <td>0.576850</td>\n",
       "      <td>0.627441</td>\n",
       "      <td>0.364455</td>\n",
       "      <td>0.939065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.346111</td>\n",
       "      <td>0.326336</td>\n",
       "      <td>0.731406</td>\n",
       "      <td>0.916090</td>\n",
       "      <td>0.972997</td>\n",
       "      <td>0.250920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936980</td>\n",
       "      <td>0.716475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2D</td>\n",
       "      <td>0.198128</td>\n",
       "      <td>0.498867</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.092414</td>\n",
       "      <td>0.139135</td>\n",
       "      <td>0.354668</td>\n",
       "      <td>0.397423</td>\n",
       "      <td>0.139545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594751</td>\n",
       "      <td>1.148364</td>\n",
       "      <td>0.114695</td>\n",
       "      <td>0.521097</td>\n",
       "      <td>0.706102</td>\n",
       "      <td>0.760472</td>\n",
       "      <td>0.038115</td>\n",
       "      <td>0.421181</td>\n",
       "      <td>0.715174</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>F359I</td>\n",
       "      <td>-0.661054</td>\n",
       "      <td>-1.103762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.521856</td>\n",
       "      <td>-0.712657</td>\n",
       "      <td>-0.480838</td>\n",
       "      <td>-0.875063</td>\n",
       "      <td>-0.606438</td>\n",
       "      <td>-0.658648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.580027</td>\n",
       "      <td>-0.554503</td>\n",
       "      <td>-0.817235</td>\n",
       "      <td>-0.369801</td>\n",
       "      <td>-0.421605</td>\n",
       "      <td>-0.336292</td>\n",
       "      <td>-0.331555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.695124</td>\n",
       "      <td>-0.192389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>F359M</td>\n",
       "      <td>-1.261642</td>\n",
       "      <td>-1.699787</td>\n",
       "      <td>-1.557662</td>\n",
       "      <td>-1.097950</td>\n",
       "      <td>-1.310086</td>\n",
       "      <td>-1.081431</td>\n",
       "      <td>-1.496837</td>\n",
       "      <td>-1.214405</td>\n",
       "      <td>-1.236343</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.177994</td>\n",
       "      <td>-1.089044</td>\n",
       "      <td>-1.389335</td>\n",
       "      <td>-0.938298</td>\n",
       "      <td>-0.989234</td>\n",
       "      <td>-0.910780</td>\n",
       "      <td>-0.906800</td>\n",
       "      <td>-1.599542</td>\n",
       "      <td>-1.294700</td>\n",
       "      <td>-0.766738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>F359P</td>\n",
       "      <td>-1.597953</td>\n",
       "      <td>-2.033542</td>\n",
       "      <td>-1.877318</td>\n",
       "      <td>-1.420545</td>\n",
       "      <td>-1.644628</td>\n",
       "      <td>-1.417744</td>\n",
       "      <td>-1.845012</td>\n",
       "      <td>-1.554848</td>\n",
       "      <td>-1.559834</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.512837</td>\n",
       "      <td>-1.388370</td>\n",
       "      <td>-1.709693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.307089</td>\n",
       "      <td>-1.232476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.931138</td>\n",
       "      <td>-1.630444</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>F359Y</td>\n",
       "      <td>1.092065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679479</td>\n",
       "      <td>1.159765</td>\n",
       "      <td>1.031240</td>\n",
       "      <td>1.272294</td>\n",
       "      <td>0.939898</td>\n",
       "      <td>1.168221</td>\n",
       "      <td>1.027644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165440</td>\n",
       "      <td>1.005825</td>\n",
       "      <td>0.852726</td>\n",
       "      <td>1.289645</td>\n",
       "      <td>1.235307</td>\n",
       "      <td>1.340641</td>\n",
       "      <td>1.347590</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>1.055040</td>\n",
       "      <td>1.484140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>F359W</td>\n",
       "      <td>0.151424</td>\n",
       "      <td>-0.297458</td>\n",
       "      <td>-0.214577</td>\n",
       "      <td>0.257486</td>\n",
       "      <td>0.095547</td>\n",
       "      <td>0.331646</td>\n",
       "      <td>-0.033924</td>\n",
       "      <td>0.216023</td>\n",
       "      <td>0.122859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228905</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>-0.043296</td>\n",
       "      <td>0.399265</td>\n",
       "      <td>0.346286</td>\n",
       "      <td>0.440878</td>\n",
       "      <td>0.446640</td>\n",
       "      <td>-0.206289</td>\n",
       "      <td>0.115984</td>\n",
       "      <td>0.584594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6707 rows  101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     full_var  pred_y_0  pred_y_1  pred_y_2  pred_y_3  pred_y_4  pred_y_5  \\\n",
       "0         Q2K  0.335646  0.635340  0.141072  0.224323  0.275930  0.492186   \n",
       "1         Q2R  0.394582       NaN       NaN  0.280856  0.334556       NaN   \n",
       "2         Q2H  0.199531  0.500259  0.011699  0.093760  0.140531  0.356071   \n",
       "3         Q2E  0.420308  0.719359  0.221542  0.305533  0.360147  0.576850   \n",
       "4         Q2D  0.198128  0.498867  0.010365  0.092414  0.139135  0.354668   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "6702    F359I -0.661054 -1.103762       NaN -0.521856 -0.712657 -0.480838   \n",
       "6703    F359M -1.261642 -1.699787 -1.557662 -1.097950 -1.310086 -1.081431   \n",
       "6704    F359P -1.597953 -2.033542 -1.877318 -1.420545 -1.644628 -1.417744   \n",
       "6705    F359Y  1.092065       NaN  0.679479  1.159765  1.031240  1.272294   \n",
       "6706    F359W  0.151424 -0.297458 -0.214577  0.257486  0.095547  0.331646   \n",
       "\n",
       "      pred_y_6  pred_y_7  pred_y_8  ...  pred_y_90  pred_y_91  pred_y_92  \\\n",
       "0     0.539792  0.278752  0.857630  ...   0.731669   1.270759        NaN   \n",
       "1     0.600807  0.338413  0.914320  ...   0.790348   1.323214   0.301831   \n",
       "2          NaN  0.140965  0.726704  ...   0.596149   1.149613   0.116032   \n",
       "3     0.627441  0.364455  0.939065  ...        NaN   1.346111   0.326336   \n",
       "4     0.397423  0.139545       NaN  ...   0.594751   1.148364   0.114695   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "6702 -0.875063 -0.606438 -0.658648  ...  -0.580027  -0.554503  -0.817235   \n",
       "6703 -1.496837 -1.214405 -1.236343  ...  -1.177994  -1.089044  -1.389335   \n",
       "6704 -1.845012 -1.554848 -1.559834  ...  -1.512837  -1.388370  -1.709693   \n",
       "6705  0.939898  1.168221  1.027644  ...   1.165440   1.005825   0.852726   \n",
       "6706 -0.033924  0.216023  0.122859  ...   0.228905   0.168627  -0.043296   \n",
       "\n",
       "      pred_y_93  pred_y_94  pred_y_95  pred_y_96  pred_y_97  pred_y_98  \\\n",
       "0      0.651267   0.836074   0.892014        NaN   0.556771   0.852460   \n",
       "1      0.707054   0.891776   0.948389   0.226279   0.614881   0.911297   \n",
       "2           NaN   0.707429   0.761814   0.039459   0.422565   0.716575   \n",
       "3      0.731406   0.916090   0.972997   0.250920        NaN   0.936980   \n",
       "4      0.521097   0.706102   0.760472   0.038115   0.421181   0.715174   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6702  -0.369801  -0.421605  -0.336292  -0.331555        NaN  -0.695124   \n",
       "6703  -0.938298  -0.989234  -0.910780  -0.906800  -1.599542  -1.294700   \n",
       "6704        NaN  -1.307089  -1.232476        NaN  -1.931138  -1.630444   \n",
       "6705   1.289645   1.235307   1.340641   1.347590   0.721164   1.055040   \n",
       "6706   0.399265   0.346286   0.440878   0.446640  -0.206289   0.115984   \n",
       "\n",
       "      pred_y_99  \n",
       "0      0.635512  \n",
       "1      0.691873  \n",
       "2      0.505344  \n",
       "3      0.716475  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "6702  -0.192389  \n",
       "6703  -0.766738  \n",
       "6704        NaN  \n",
       "6705   1.484140  \n",
       "6706   0.584594  \n",
       "\n",
       "[6707 rows x 101 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_am_ohllr_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ad2a52-c05a-4476-a9d8-4aac7fee850c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_y_100\n",
      "pred_y_101\n",
      "pred_y_102\n",
      "pred_y_103\n",
      "pred_y_104\n",
      "pred_y_105\n",
      "pred_y_106\n",
      "pred_y_107\n",
      "pred_y_108\n",
      "pred_y_109\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    string = f\"pred_y_{i+100}\"\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e7ecbc5-7c42-4173-b566-149cb8bdc705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>full_var</th>\n",
       "      <th>wt_aa</th>\n",
       "      <th>var_aa</th>\n",
       "      <th>am_pathogenicity</th>\n",
       "      <th>ESM1b_score</th>\n",
       "      <th>Expr_z_score</th>\n",
       "      <th>Migr_z_score</th>\n",
       "      <th>Prolif_z_score</th>\n",
       "      <th>logit_am_path</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_8606</th>\n",
       "      <th>feature_8607</th>\n",
       "      <th>feature_8608</th>\n",
       "      <th>feature_8609</th>\n",
       "      <th>feature_8610</th>\n",
       "      <th>feature_8611</th>\n",
       "      <th>feature_8612</th>\n",
       "      <th>feature_8613</th>\n",
       "      <th>feature_8614</th>\n",
       "      <th>feature_8615</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2K</td>\n",
       "      <td>Q</td>\n",
       "      <td>K</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-4.919</td>\n",
       "      <td>-1.464268</td>\n",
       "      <td>0.41329</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>-2.353348</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2R</td>\n",
       "      <td>Q</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>-3.915</td>\n",
       "      <td>-0.228183</td>\n",
       "      <td>-0.668042</td>\n",
       "      <td>0.709616</td>\n",
       "      <td>-2.523894</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2H</td>\n",
       "      <td>Q</td>\n",
       "      <td>H</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>-4.331</td>\n",
       "      <td>0.430181</td>\n",
       "      <td>-0.829473</td>\n",
       "      <td>-0.09298</td>\n",
       "      <td>-2.031842</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2E</td>\n",
       "      <td>Q</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>1.027485</td>\n",
       "      <td>-0.728391</td>\n",
       "      <td>-0.677382</td>\n",
       "      <td>-2.606832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2D</td>\n",
       "      <td>Q</td>\n",
       "      <td>D</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>-2.215</td>\n",
       "      <td>1.271945</td>\n",
       "      <td>-1.463108</td>\n",
       "      <td>-0.864939</td>\n",
       "      <td>-2.028918</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>359</td>\n",
       "      <td>F359I</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>-5.377</td>\n",
       "      <td>0.329759</td>\n",
       "      <td>0.18287</td>\n",
       "      <td>-1.074683</td>\n",
       "      <td>0.827849</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>359</td>\n",
       "      <td>F359M</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>-5.422</td>\n",
       "      <td>0.56399</td>\n",
       "      <td>-1.152813</td>\n",
       "      <td>-1.426938</td>\n",
       "      <td>1.545757</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>359</td>\n",
       "      <td>F359P</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>-6.241</td>\n",
       "      <td>1.228805</td>\n",
       "      <td>-1.285548</td>\n",
       "      <td>-0.505204</td>\n",
       "      <td>2.155698</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>359</td>\n",
       "      <td>F359Y</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.3211</td>\n",
       "      <td>-7.047</td>\n",
       "      <td>0.970892</td>\n",
       "      <td>0.100578</td>\n",
       "      <td>1.512123</td>\n",
       "      <td>-0.748721</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>359</td>\n",
       "      <td>F359W</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-6.702</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>0.177008</td>\n",
       "      <td>0.360717</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6707 rows  8626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos full_var wt_aa var_aa am_pathogenicity ESM1b_score Expr_z_score  \\\n",
       "0       2      Q2K     Q      K           0.0868      -4.919    -1.464268   \n",
       "1       2      Q2R     Q      R           0.0742      -3.915    -0.228183   \n",
       "2       2      Q2H     Q      H           0.1159      -4.331     0.430181   \n",
       "3       2      Q2E     Q      E           0.0687       -1.64     1.027485   \n",
       "4       2      Q2D     Q      D           0.1162      -2.215     1.271945   \n",
       "...   ...      ...   ...    ...              ...         ...          ...   \n",
       "6702  359    F359I     F      I           0.6959      -5.377     0.329759   \n",
       "6703  359    F359M     F      M           0.8243      -5.422      0.56399   \n",
       "6704  359    F359P     F      P           0.8962      -6.241     1.228805   \n",
       "6705  359    F359Y     F      Y           0.3211      -7.047     0.970892   \n",
       "6706  359    F359W     F      W           0.5222      -6.702    -0.143099   \n",
       "\n",
       "     Migr_z_score Prolif_z_score logit_am_path  ... feature_8606 feature_8607  \\\n",
       "0         0.41329       0.299999     -2.353348  ...            0            0   \n",
       "1       -0.668042       0.709616     -2.523894  ...            0            0   \n",
       "2       -0.829473       -0.09298     -2.031842  ...            0            0   \n",
       "3       -0.728391      -0.677382     -2.606832  ...            0            0   \n",
       "4       -1.463108      -0.864939     -2.028918  ...            0            0   \n",
       "...           ...            ...           ...  ...          ...          ...   \n",
       "6702      0.18287      -1.074683      0.827849  ...            0            0   \n",
       "6703    -1.152813      -1.426938      1.545757  ...            0            0   \n",
       "6704    -1.285548      -0.505204      2.155698  ...            1            0   \n",
       "6705     0.100578       1.512123     -0.748721  ...            0            0   \n",
       "6706     0.177008       0.360717      0.088858  ...            0            0   \n",
       "\n",
       "     feature_8608 feature_8609 feature_8610 feature_8611 feature_8612  \\\n",
       "0               0            0            1            0            0   \n",
       "1               0            0            1            0            0   \n",
       "2               0            0            1            0            0   \n",
       "3               0            0            1            0            0   \n",
       "4               0            0            1            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "6702            0            1            0            0            0   \n",
       "6703            0            0            0            0            0   \n",
       "6704            0            0            0            0            0   \n",
       "6705            0            0            0            1            0   \n",
       "6706            0            0            0            0            1   \n",
       "\n",
       "     feature_8613 feature_8614 feature_8615  \n",
       "0               0            0            0  \n",
       "1               0            0            0  \n",
       "2               0            0            0  \n",
       "3               0            0            0  \n",
       "4               0            0            0  \n",
       "...           ...          ...          ...  \n",
       "6702            0            0            0  \n",
       "6703            0            0            0  \n",
       "6704            0            0            0  \n",
       "6705            0            0            0  \n",
       "6706            0            0            0  \n",
       "\n",
       "[6707 rows x 8626 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe_logit_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d88e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ed4930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy version: 1.24.3\n",
      "pandas version: 1.5.3\n",
      "scipy version: 1.10.1\n"
     ]
    },
    {
     "ename": "DistributionNotFound",
     "evalue": "The 'scikit' distribution was not found and is required by the application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDistributionNotFound\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print each package's version\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m package \u001b[38;5;129;01min\u001b[39;00m packages:\n\u001b[1;32m---> 10\u001b[0m     version \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mget_distribution(package)\u001b[38;5;241m.\u001b[39mversion\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScikit-learn version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sklearn\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pkg_resources\\__init__.py:528\u001b[0m, in \u001b[0;36mget_distribution\u001b[1;34m(dist)\u001b[0m\n\u001b[0;32m    526\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Requirement\u001b[38;5;241m.\u001b[39mparse(dist)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Requirement):\n\u001b[1;32m--> 528\u001b[0m     dist \u001b[38;5;241m=\u001b[39m get_provider(dist)\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Distribution):\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected string, Requirement, or Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pkg_resources\\__init__.py:400\u001b[0m, in \u001b[0;36mget_provider\u001b[1;34m(moduleOrReq)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m working_set\u001b[38;5;241m.\u001b[39mfind(moduleOrReq) \u001b[38;5;129;01mor\u001b[39;00m require(\u001b[38;5;28mstr\u001b[39m(moduleOrReq))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[moduleOrReq]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pkg_resources\\__init__.py:968\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[1;34m(self, *requirements)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mrequirements):\n\u001b[0;32m    960\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \n\u001b[0;32m    962\u001b[0m \u001b[38;5;124;03m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;124;03m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 968\u001b[0m     needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve(parse_requirements(requirements))\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m needed:\n\u001b[0;32m    971\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(dist)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pkg_resources\\__init__.py:829\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[1;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m req_extras\u001b[38;5;241m.\u001b[39mmarkers_pass(req, extras):\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 829\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_dist(\n\u001b[0;32m    830\u001b[0m     req, best, replace_conflicting, env, installer, required_by, to_activate\n\u001b[0;32m    831\u001b[0m )\n\u001b[0;32m    833\u001b[0m \u001b[38;5;66;03m# push the new requirements onto the stack\u001b[39;00m\n\u001b[0;32m    834\u001b[0m new_requirements \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mrequires(req\u001b[38;5;241m.\u001b[39mextras)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pkg_resources\\__init__.py:870\u001b[0m, in \u001b[0;36mWorkingSet._resolve_dist\u001b[1;34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m             requirers \u001b[38;5;241m=\u001b[39m required_by\u001b[38;5;241m.\u001b[39mget(req, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 870\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DistributionNotFound(req, requirers)\n\u001b[0;32m    871\u001b[0m     to_activate\u001b[38;5;241m.\u001b[39mappend(dist)\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m req:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;66;03m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n",
      "\u001b[1;31mDistributionNotFound\u001b[0m: The 'scikit' distribution was not found and is required by the application"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "import pkg_resources\n",
    "\n",
    "# List of package names you want to check versions for\n",
    "packages = ['numpy', 'pandas', 'scipy', 'scikit']\n",
    "\n",
    "# Print each package's version\n",
    "for package in packages:\n",
    "    version = pkg_resources.get_distribution(package).version\n",
    "    print(f\"{package} version: {version}\")\n",
    "    \n",
    "print(\"Scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd9340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
